[
	
		{
		  "title" : "Migrating from state_machine to aasm in Rails",
		  "category" : "technology",
		  "url" : "/technology/migrating-from-state-machine-to-aasm-in-rails/",
		  "date" : "2018-06-29 00:00:00 +0530",
		  "content"	: "First things first. State machines are awesome , be it any part of technology you use them in.<br /><br />Recently at work , we passed many pipelines on migrating a very large Rails app from Rails 4 to Rails 5. One of the major parts of this change was shifting from state_machine to aasm for our state transitions. We rely heavily on state machines for how our instances shift states. Much of our tasks associated with the models too are integrated with the after/before actions of our state machines.<br /><br /><br /><br />Need for transition:<br /><br />One and only one reason , state_machine has been dead , and for quite some time. We shifted from Rails 3.2 to Rails 4.2 last year , and since it was a really , really painful migration , we fixed our focus on changed syntax and ActiveJob , found the much famous monkeypatch for Rails 4.2 and stayed happy for the time being with state_machine. Though there is state_machines_activerecord , we wanted to move to a more reliable and tested library , and as we already use acts_as_state_machine or aasm in one of our other projects , we tried and gave it a shot , when we began our Rails 5 voyage , for which of course neither state_machine and its patch worked , nor it was recommended.<br /><br />What changed:<br /><br />As it turned out , the process was not too messy. After a small study of the way both state_machine and aasm handle state transitions , one can easily find an analogy. Here are a few things which usually are a part of a state_machine laden project and how they should be modified to work with aasm<br /><br />1. The gem itself<br /><br />Goes without saying , remove from your Gemfile/gems.rb :<br /><br />  gem &amp;#39;state_machine&amp;#39;<br /><br />and add :<br /><br />  gem &amp;#39;aasm&amp;#39;<br /><br />2. Get rid of the state_machine monkey-patch if present<br /><br />  module StateMachine<br />    module Integrations<br />      module ActiveModel<br />        public :around_validation<br />      end<br />      module ActiveRecord<br />        public :around_save<br />        def define_state_initializer<br />          define_helper :instance , &#60;;&#60;;-end_eval , __FILE__ , __LINE__ + 1<br />            def initialize(*)<br />              super do |*args|<br />                self.class.state_machines.initialize_states self<br />                yield(*args) if block_given?<br />              end<br />            end<br />          end_eval<br />        end<br />      end<br />    end<br />  end<br /><br />Yes , get rid of this if you have it , most probably in one of your config/initializers.<br /><br />3. Transitioning the transitions:<br /><br />This is the major part of the change and yet the easiest to implement. This includes code change in models. Take a look at the documentation over at aasm and start changing the code. Here are a few pointers.<br /><br />add include AASM to your model<br /><br />  class Question &#60;; ActiveRecord::Base<br />    include AASM<br />    ...<br />  end<br /><br />specify the column name on which you are observing state transitions , for eg. if the column name is state<br /><br />  class Question &#60;; ActiveRecord::Base<br />    include AASM<br />    ...<br />    aasm.attribute_name :state<br />    ...<br />  end<br /><br />Initiate your state machine block by listing out all your states. The common way is using one line to specify your initial state , and a second line to list all your non-initial states<br /><br />  class Question &#60;; ActiveRecord::Base<br />    include AASM<br />    ...<br />    aasm.attribute_name :state<br />    aasm do<br />      state :authored , initial: true<br />      state :piloted , :non_active , :active , :removed<br />      ...<br />    end<br />    ...<br />  end<br /><br />Convert your events. All event blocks of the form transition :a =&#62;; :b will be replaced by transitions from: :a , to: :b<br /><br />  class Question &#60;; ActiveRecord::Base<br />    include AASM<br />    ...<br /><br />    # State machine code<br /><br />    state_machine :state , initial: :authored do<br /><br />      event :pilot do<br />        transition :authored =&#62;; :piloted<br />      end<br /><br />      event :activate do<br />        transition [:piloted , :non_active] =&#62;; :active<br />      end<br /><br />      ..<br />    end<br /><br /><br />   # AASM code<br /><br />    aasm.attribute_name :state<br />    aasm do<br />      state :authored , initial: true<br />      state :piloted , :non_active , :active , :removed<br /><br />      event :pilot do<br />        transitions from: :authored , to: :piloted<br />      end<br /><br />      event :activate do<br />        transitions from: [:piloted , :non_active] , to: :active<br />      end<br /><br />      ...<br />    end<br />    ...<br />  end<br /><br />Callbacks like before_transition and after_transition from state_machine can be converted like this:<br /><br />  class Question &#60;; ActiveRecord::Base<br />    include AASM<br />    ...<br /><br />    # State machine code<br /><br />    state_machine :state , initial: :authored do<br />      before_transition :authored =&#62;; :piloted , :do =&#62;; :prepare_cockpit<br />      after_transition :authored =&#62;; :piloted , :do =&#62;; :fly_the_plane<br /><br />      event :pilot do<br />        transition :authored =&#62;; :piloted<br />      end<br />      ...<br />    end<br /><br />    # AASM code<br /><br />    aasm.attribute_name :state<br />    aasm do<br />      state :authored , initial: true<br />      state :piloted , :non_active , :active , :removed<br /><br />      event :pilot do<br />        before do<br />          prepare_cockpit<br />        end<br />        transitions from: :authored , to: :piloted , after: :fly_the_plane<br />      end<br /><br />      ...<br />    end<br />    ...<br /><br />    def prepare_cockpit<br />      ...<br />    end<br /><br />    def fly_the_plane<br />      ...<br />    end<br /><br /><br />  end<br /><br />However , in case of callbacks on a part of a transitions defined inside an event , one needs to define the transitions separately<br /><br />  class Question &#60;; ActiveRecord::Base<br />    include AASM<br />    ...<br /><br />    # State machine code<br /><br />    state_machine :state , initial: :authored do<br />      after_transition :authored =&#62;; :piloted , :do =&#62;; :fly<br /><br />      event :pilot do<br />        transition [:inactive , :authored] =&#62;; :piloted<br />      end<br />      ...<br />    end<br /><br />    # AASM code<br /><br />    aasm.attribute_name :state<br />    aasm do<br />      state :authored , initial: true<br />      state :piloted , :non_active , :active , :removed<br /><br />      event :pilot do<br />        transitions from: :authored , to: :piloted , after: :fly<br />        transitions from: :inactive , to: :piloted<br />      end<br /><br />      ...<br />    end<br />    ...<br /><br />    def fly<br />      ...<br />    end<br /><br />  end<br /><br />if and unless guard blocks on transitions work the same way as in state_machine , and can also be substituted with a guard clause. The guards as well as callbacks can take arguments , lambda as well as Proc , same as the state machine guards<br /><br />  class Question &#60;; ActiveRecord::Base<br />    include AASM<br />    ...<br /><br />    # State machine code<br /><br />    state_machine :state , initial: :authored do<br /><br />      event :pilot do<br />        transition :authored =&#62;; :piloted , if: :can_fly?<br />      end<br />      ...<br />    end<br /><br />    # AASM code<br /><br />    aasm.attribute_name :state<br />    aasm do<br />      state :authored , initial: true<br />      state :piloted , :non_active , :active , :removed<br /><br />      event :pilot do<br />        transitions from: :authored , to: :piloted , guard: :can_fly?<br />      end<br /><br />      ...<br />    end<br />    ...<br /><br />    def can_fly?<br />      ...<br />    end<br /><br />  end<br /><br />Yes , that’s it for the models. You can take a detailed look at the docs if you have more complex needs.<br /><br />4. The helpers:<br /><br />One plus point for state_machine  , it has/had a variety of useful helpers for making use of states and events in views and controllers. aasm , though lagging behind a little in this domain , still has a good pool of helpers , both class and instance to make good use of. Here are some pointers.<br /><br /><br />  Question.aasm.states will give you an object list of all states available for the Question model<br />  Question.aasm.events will give you an object list of all events available for the Question model<br />  Question.first.aasm.states will give an object list of all states available for transitioning to for a Question object , in this case the first one.<br />  Question.first.aasm.events will give an object list of all events that can be applied on the current state of the Question object , i.e the first<br />  All of the above helpers will produce an object list that contains name as the name of object , so appending .map(&amp;amp;:name) will give a symbol array of the name of objects , that will come handy in drop-downs. Eg.<br /><br /><br />  pry(main)&#62;; Question.last.aasm.events.map(&amp;amp;:name)<br />  =&#62;; [:pilot , :deactivate]<br /><br />Another great point in favor of state_machine is its state_event attribute over the instance. For eg.<br /><br />  pry(main)&#62;; question = Question.first<br />  pry(main)&#62;; question.state_event = :deactivate<br />  pry(main)&#62;; question.save<br /><br />The code above will end up saving the question after calling the deactivate event over it. This attribute is highly useful in rails forms where one can easily pass what event to call from , and the transition will happen without extra hassle. Unfortunately , there’s no equivalent attribute cum method in aasm . But one can always write a common ActiveRecord::Base helper for the same.<br /><br />On another note , the not-so-good-looking with_state / with_states scope methods of state_machine can be replaced by the enum equivalent syntax of aasm . For eg.<br /><br />  Question.with_state(:active) # state_machine<br /><br />gets replaced by a much cleaner :<br /><br />  Question.active<br /><br />So yes , a couple of tweaks here and there , and a good pool of existing test cases which run green , you are done and production ready. This will get you started , but do back yourself up with the aasm docs.<br />"
		} ,
	
		{
		  "title" : "Android Versioning Using Docker &amp; Git Like A Pro",
		  "category" : "technology",
		  "url" : "/technology/android-versioning-using-docker-and-git-like-a-pro/",
		  "date" : "2018-06-10 00:00:00 +0530",
		  "content"	: "Unlike web , android still lacks the ease of version deployments. Specially when you don’t want to use Play Store.<br /><br />Introduction<br /><br />There will be five stages:<br /><br /><br />  Signing application<br />  Versioning of application. For that we gonna use git revision and Major.Minor.Patch naming convention.<br />  Building application using a docker. So that running environment doesn’t change.<br />  Pushing new release to s3 , while maintaining the previous versions.<br />  Pushing new tag to git , with the new version. So , we’ll have tags for each version.<br /><br /><br />Basically , we gonna use docker , git , and some simple hacks to put things in work. In the end , I’ve shared a sample application.<br /><br />Stage 1: Signing Our Application<br /><br />It’s better to start thinking about security right from the big bang.<br />From android studio , you can generate a new keystore , a jks file. Help?<br />Copy the keystore file details in a config.yaml file like below:<br /><br />key_store:<br />  key: /xyz/xyz.jks<br />  alias: key0<br />  store_password: wuhoo<br />  key_password: nibataunga<br /><br />Studio will take care of signing , but to generate signed apk from command line , you’ll need to make some changes in your build.gradle. The credentials we have put in above yaml file will be passed as command line args to gradle(Build stage[2]).<br /><br />android {<br />    ...<br />    signingConfigs {<br />        release {<br />            if (project.hasProperty(&amp;#39;APP_RELEASE_STORE_FILE&amp;#39;)) {<br />                storeFile file(&ldquo;$APP_RELEASE_STORE_FILE&ldquo;)<br />                storePassword &ldquo;$APP_RELEASE_STORE_PASSWORD&ldquo;<br />                keyAlias &ldquo;$APP_RELEASE_KEY_ALIAS&ldquo;<br />                keyPassword &ldquo;$APP_RELEASE_KEY_PASSWORD&ldquo;<br />            }<br />        }<br />    }<br />    buildTypes {<br />        release {<br />          ...<br />          if (project.hasProperty(&amp;#39;APP_RELEASE_STORE_FILE&amp;#39;)) {<br />              signingConfig signingConfigs.release<br />          }<br />        }<br />    }<br />}<br /><br />Stage 2: Release Versioning , Digging Git<br /><br />I’am here using the semantic versioning.<br /><br />Major.Minor.GitRevision.Patch<br /><br />Let’s dig into GitRevision<br />It counts the number of commits from git , so you’ll get incremental values everytime you release a new version. GitRevision will make versioning easy and consistent.<br /><br />We’ll put the below code in build.gradle[app]<br /><br />def getGitRevision = { -&#62;;<br />    try {<br />        def stdout = new ByteArrayOutputStream()<br />        exec {<br />            standardOutput = stdout<br />            commandLine &amp;#39;git&amp;#39; , &amp;#39;rev-list&amp;#39; , &amp;#39;--first-parent&amp;#39; , &amp;#39;--count&amp;#39; , &amp;#39;master&amp;#39;<br />        }<br />        logger.info(&ldquo;Building revision #&ldquo;+stdout)<br />        return stdout.toString(&ldquo;ASCII&ldquo;).trim().toInteger()<br />    }<br />    catch (Exception e) {<br />        e.printStackTrace();<br />        return 0;<br />    }<br />}<br /><br />And in build.gradle[app]<br /><br />    defaultConfig {<br />        ...<br />        versionCode = 10000000*majorVersion+10000*minorVersion + 10*revision<br />        versionName = &amp;#39;v&amp;#39; + majorVersion + &amp;#39;.&amp;#39; + minorVersion + &amp;#39;.&amp;#39; + revision + patch<br />    }<br /><br />Docker Image , Savage<br /><br />We first need to build a docker image with minimum libraries and dependencies required.<br /><br />FROM openjdk:8<br />RUN apt-get update<br />RUN cd /opt/<br />RUN wget -nc https://dl.google.com/android/repository/sdk-tools-linux-4333796.zip<br />ENV ANDROID_HOME /opt/android-sdk-linux<br />RUN mkdir -p ${ANDROID_HOME}<br />RUN unzip -n -d ${ANDROID_HOME} sdk-tools-linux-4333796.zip<br />ENV PATH ${PATH}:${ANDROID_HOME}/tools:${ANDROID_HOME}/tools/bin:${ANDROID_HOME}/platform-tools<br />RUN yes | sdkmanager --licenses<br />RUN yes | sdkmanager \<br />      &ldquo;platform-tools&ldquo; \<br />      &ldquo;build-tools;27.0.3&ldquo; \<br />      &ldquo;platforms;android-27&ldquo;<br /><br />RUN apt-get -y install ruby<br />RUN gem install trollop<br /><br />Trollop will be helpful in compiling scripts , spicing the boring command line args.<br /><br />We are using openjdk as base image for java environment and installed our sdk with version 27. You can change that accordingly.<br /><br />Building the image:<br /><br />docker build -t ${docker_image} -f ./scripts/Dockerfile .<br /><br />Or you can directly pull my latest base image.<br /><br />docker pull mukarramali98/androidbase<br /><br />Docker container on the way<br /><br />To automate the process , let’s dig into a small script:<br /><br />#!/usr/bin/env bash<br />set -xeuo pipefail<br /><br />app_name=xyz<br />container_name=androidcontainer<br /><br />if [ ! &ldquo;$(docker ps -q -f name=${container_name})&ldquo; ]; then<br />    if [ &ldquo;$(docker ps -aq -f status=exited -f name=${container_name})&ldquo; ]; then<br />        # cleanup<br />        docker rm $container_name<br />    fi<br />    # run your container<br />    docker run -v ${PWD}:/${app_name}/ --name ${container_name} -w /${app_name} -d -i -t mukarramali98/androidbase<br />fi<br /><br />docker exec ${container_name} ruby /${app_name}/scripts/compile.rb -k /${app_name}/config.yaml<br /><br />Here we first check if the container already exists. Then create accordingly.<br />While creating the container , we mount our current project directory. So next time we run this container , our updated project will already be there in the container.<br /><br />Stage 3: Running container , Build Stage<br /><br />We run the container , with our compile script. Pass the signing config file we created earlier.<br /><br />config = YAML.load_file(key_config_file)<br /><br />key_store = config[&amp;#39;key_store&amp;#39;]<br />output_file = &amp;#39;app/build/outputs/apk/release/app-release.apk&amp;#39;<br />`rm #{output_file}` if File.exists?output_file<br /><br />puts `#{File.dirname(__FILE__)}/../gradlew assembleRelease --stacktrace \<br />    -PAPP_RELEASE_STORE_FILE=#{key_store[&amp;#39;key&amp;#39;]} \<br />    -PAPP_RELEASE_KEY_ALIAS=#{key_store[&amp;#39;alias&amp;#39;]} \<br />    -PAPP_RELEASE_STORE_PASSWORD=&amp;#39;#{key_store[&amp;#39;store_password&amp;#39;]}&amp;#39; \<br />    -PAPP_RELEASE_KEY_PASSWORD=&amp;#39;#{key_store[&amp;#39;key_password&amp;#39;]}&amp;#39;`<br /><br />Stage 4: Pushing to S3<br /><br />So , now we have build a signed apk from a docker container. It’s time to push them.<br />Connect with your s3 bucket and generate $HOME/.s3cfg file , and pass it to ruby script below:<br /><br />if File.file?(s3_config)<br />  # Push the generate apk file with the app and version name<br />  `s3cmd put app/build/outputs/apk/release/app-release.apk s3://#{bucket}/#{app_name}-#{version_name}.apk -m application/vnd.android.package-archive -f -P -c #{s3_config}`<br />  # application/vnd.android.package-archive is an apk file format descriptor<br /><br />  # Replace the previous production file<br />  `s3cmd put app/build/outputs/apk/release/app-release.apk s3://#{bucket}/#{app_name}.apk -m application/vnd.android.package-archive -f -P -c #{s3_config}`<br /><br />  # To keep the track of latest release<br />  `echo #{version_code}&#62;; latest_version.txt`<br />  `s3cmd put latest_version.txt s3://#{bucket}/latest_version.txt -f -P -c #{s3_config}`<br />  `rm latest_version.txt`<br />  puts &ldquo;Successfully released new app version.&ldquo;<br />end<br /><br />application/vnd.android.package-archive is the apk file type descriptor.<br /><br />Stage 5: Finally , Git Tagging The New Release Version , #hashtag<br /><br />def push_new_tag version_name<br />  `git tag #{version_name}`<br />  `git push origin #{version_name}`<br />  puts &ldquo;New tag pushed to repo.&ldquo;<br />end<br /><br />Demo Application<br />"
		} ,
	
		{
		  "title" : "How Tough is it to Score Well in Board Exams?",
		  "category" : "career",
		  "url" : "/career/how-tough-is-it-to-score-well-in-board-exams/",
		  "date" : "2018-02-22 00:00:00 +0530",
		  "content"	: "I completed my entire schooling (Classes I through XII) at one of Kolkata’s favoured catholic schools. In those days , discipline and academic excellence were the primary parameters that mattered and my school checked both these boxes rather well.<br /><br /><br />Trouble started brewing once I graduated to Class XI and started thinking about higher education , specifically opportunities at the national level. That’s when I truly realized the impact of the education board. In my case , the impact was limited to a couple of aspects , viz. a) subjects / topics not covered in the Bengal board syllabus , and b) the frugality in awarding marks.<br /><br />Fortunately , some extra tuitions covered up for the former , while the latter did not come into play at all in any of the options I signed up for , or in the higher education option I finally opted for.<br /><br />Times have changed….<br /><br />For a few years , till 2016 , 40% weightage was accorded to an applicant’s Class XII board marks in calculating her All India Rank in the JEE (entrance tests for admission to India’s flagship IITs , and a few other engineering schools) exams. However , since 2017 , the rules were changed to treat the Class XII marks as a qualifying criterion: a minimum of 75% marks , or a rank in the top 20th percentile in the board.<br /><br />The 75% cut-off may appear inconsequential to folks intimately familiar with the CBSE or ISCE boards , but not all students find it amusing. The JEE implementation committee publishes the 80th percentile cut-off marks for every higher secondary educational board in the country to level the playing field. Finally , we have access to data that clearly shows the disparity in awarding marks across boards in India.<br /><br />According to data for the 2016 Class XII exams , the 5 most liberal boards are (percentages indicate the 80th percentile cut-off score):<br /><br />  Telengana Board of Secondary Education (95%)<br />  Andhra Pradesh Board of Intermediate Education (94%)<br />  Council for the Indian School Certificate Examinations (88.6%)<br />  Banasthali Vidyapeeth , Rajasthan (87.4%)<br />  Tamil Nadu Board of Higher Secondary Education (87.2)<br /><br /><br />While the 4 most frugal boards are:<br /><br />  Tripura Board of Secondary Education (59.8%)<br />  Jharkhand Academic Council (60.6%)<br />  Meghalaya Board of Secondary Education (61.6%)<br />  Odisha Council of Higher Secondary Education (62%)<br />  Bihar Intermediate Education Council (63%)<br /><br /><br />What this essentially means is that a student scoring 95% in the Telengana board exams is academically comparable to a student scoring 60.6% in the Jharkhand board exams , despite a whopping 34.6% gap is scores!<br /><br />The data clearly shows how a single mark-based cut-off or a mark-based weightage criterion can result in gross injustice to students from boards that are frugal in awarding marks! Thankfully , the JEE implementation committee , in its infinite wisdom , has taken steps to normalize this inherent disparity.<br /><br />Time will tell whether the practice of allotting an explicit or implicit weightage to board exam performance will become the norm , not only in JEE but in other national level entrance tests as well. But for now , this is definitely something for parents to consider while looking for a school for their children.<br /><br />But what about employment? It is common practice among potential employers to set mark-based cut-offs for board exams (while hiring entry-level talent) , among others. And in almost all cases , the cut-off is a single number applicable across the board (pun intended!).<br /><br />Let’s say company X sets a Class XII marks cut-off at 75%. Referring to the 10 boards listed above , company X will end up considering a population far larger than the top quintile from to 5 most generous states , and a population far smaller than the top quintile in the 5 most frugal states. The playing field is not so level anymore…..<br />"
		} ,
	
		{
		  "title" : "It's the Attitude, Stupid!",
		  "category" : "career",
		  "url" : "/career/its-the-attitude-stupid/",
		  "date" : "2017-12-19 00:00:00 +0530",
		  "content"	: "Congratulations on your first job! So you cleared the selection process; cracked some tests maybe , shone through a group discussion possibly , and impressed and charmed your way through the interviews. Well done!<br /><br /><br />You’ve been assessed and found suitable for the job on offer. No more evaluations , no more assessments. Right?<br /><br />Wrong! Let’s get one thing straight. This is just the beginning of your evaluation. What you’ve achieved (and by no means is it trivial) is to convince your future employer that you have potential. However , from day one in your first job , you will be continuously assessed on what you deliver.<br /><br />For whatever it’s worth , taking the liberty to share a cheat sheet that may help in ensuring that promise does translate to delivery in the first couple of years in your career. And be warned that it’s all in the attitude…<br /><br />Cheat 1<br />Sumadhur was undoubtedly brilliant. Armed with a degree from India’s best engineering school , he was given complex tasks in line with his academic record and promise.<br /><br />However , very soon , his manager realised that he was not able to complete most of his tasks. The manager tried to find probable reasons behind such repeated failures. Soon , he realised that Sumadhur was not open to data , insights or feedback that conflicted with his own assumptions and beliefs.<br /><br />Tell yourself at least once each day: “I do not know anything. I am here to learn and apply.”<br /><br />Cheat 2<br />Abhinav had completed just 6 months in his first job , but had been upset for a while. His friends earned twice as much as him , despite working fewer hours than he did. They seemed to be having a rollicking time! Abhinav started looking around and got a 50% higher offer. He took the offer up with glee. Not only was the pay better , but the work was less demanding and had relaxed deadlines. Life could not be better…<br /><br />Two years down the line , Abhinav started looking for yet another change , and yet another quantum leap in compensation. However , he found , to his dismay , that he was way out of depth and no company was willing to make him an offer.<br /><br />Convince yourself that reward follows performance , and not the other way around.<br /><br />Cheat 3<br />Kanu was very sharp. However , four years of hostel life had turned his biological clock upside down. When he did make it to office during normal working hours , he excelled in his tasks. Unfortunately , on most days , he simply could not.<br /><br />Within six months , he was asked to leave.<br /><br />Change your college habits to the extent required , so as to ensure that you are available (and awake!) when your work and / or team needs you to be.<br /><br />Cheat 4<br />Manish was a star in college. He excelled in academics and was popular among students as well. Out of sheer habit , he continued behaving in a brash manner with his peers in the workplace.<br /><br />He was counselled by his manager , but was unable to mend his ways in time and was asked to leave.<br /><br />Accept the fact that you need to interact with people across age groups and cultures. You are not expected to like or respect one and all (after all , respect is earned!). However , you are expected to treat one and all with respect.<br /><br />"
		} ,
	
		{
		  "title" : "Fishing in Troubled Waters",
		  "category" : "the other side",
		  "url" : "/the-other-side/fishing-in-troubled-waters/",
		  "date" : "2017-12-19 00:00:00 +0530",
		  "content"	: "Back in my final year in college , I applied for a job at an FMCG major hiring for Techno-managerial roles. I cleared the eligibility criteria and the group discussion. The short and not-so-sweet interview went something like this:<br /><br /><br />Q: Did you apply to any core companies?<br /><br />A: Yes , I applied to X and Y.<br /><br />Q: What happened?<br /><br />A: I did not clear the written test.<br /><br />Q: What were the tests about?<br /><br />A: They were technical tests.<br /><br />Q: Why do you think you did not clear?<br /><br />A: Majority of questions were from courses taught in my second year. Since I had not brushed up on concepts , I could not answer many questions.<br /><br />Q: We expect our hires to know their domain. We cannot train them. It’s clear that you do not know your domain. Thank you for your time.<br /><br />A: (Thinking)… wow what just happened???<br /><br />I was asked the same set questions in a subsequent interview and , needless to say , I did not repeat all my answers (though I did not lie). The irony of it all is that , not only was I made an offer , I accepted the offer , spent 8 years in that organization and did fairly well in a core technical role!<br /><br />Since I moved over to the other side , I have kept revisiting to my own experience in that FMCG interview. My key takeaways are:<br /><br /><br />  <br />    Aptitude or natural ability matters orders more than knowledge in a particular domain , especially in entry level roles.<br />  <br />  <br />    In today’s dynamic landscape , it is almost guaranteed that specific skills will become obsolete with time. Therefore , the relevance of employees will persist only if they have the ability to learn new skills. Once again , natural ability and mindset will come to the fore.<br />  <br />  <br />    There was no Google in those days. Nor had anyone imagined Facebook , LinkedIn or Twitter. Today , any half-serious candidate can dig up a bunch of information on a company’s recruitment process , right down to the kind of questions asked in tests and interviews , in no time whatsoever. Generic questions will lead to rehearsed “correct” answers , which have no correlation with the actual aptitude , mindset , skill or aspirations of the candidate.<br />  <br /><br /><br />I find it amusing that many organizations still follow the same two-decade old formulae to hire people. To be sure , it may very well work for certain organizations. However , it is worth taking a dispassionate look at whether your process indeed works like you expect it to. Are you convinced that you are not ending up hiring the “wrong” folks , or worse , missing out on the “right” ones?<br />"
		} ,
	
		{
		  "title" : "Hiring may be Rocket Science, but its Tenets are Basic",
		  "category" : "the other side",
		  "url" : "/the-other-side/hiring-may-be-rocket-science-but-its-tenets-are-basic/",
		  "date" : "2017-10-24 00:00:00 +0530",
		  "content"	: "Hiring is as old as employment itself. We are talking about a time period of a few thousand years – not a fact to be trifled with. The methods , tools and approaches may have changed and evolved with time , but I believe that it’s safe to say that the underlying principles would not have changed much.<br /><br /><br />Recall instances where you were evaluating a potential candidate - and it does not matter whether you were looking for someone to help out at home , or someone to drive your vehicle , or someone to join your team at work. Consciously or subconsciously you would be ticking checkboxes against these basic principles… Not convinced? Okay , allow me to lay them out for you – I’ll stick my neck out on this one.<br /><br />Tenet 1<br /><br />Notwithstanding his ability with the bat , fitness levels and mental strength , would MS Dhoni have been successful as an opener in Test Cricket? Most likely not!<br /><br />What are you assessing?<br />Does she have an aptitude for this job? In other words , does she have a natural ability to perform this job?<br /><br />Tenet 2<br /><br />An ex-colleague of mine , a product of India’s best t-school , was undoubtedly brilliant. However , he consistently failed to meet his goals. Reason: either lost interest in the last mile , or buckled under deadline pressures. Sounds familiar?<br /><br />What are you assessing?<br />Does she have the right mindset? How often have we seen – and heart wrenchingly so – that aptitude alone cannot and does not guarantee success on the job?<br /><br />Tenet 3<br /><br />Ever wondered why a majority of software developers are engineers?<br /><br />What are you assessing?<br />Does she have the necessary skills? Skills could be knowledge , experience or even academic qualification? Even if you have a top class training facility at your disposal , your fresh hires will need a minimum set of pre-existing skills that are critical to succeed.<br /><br />Tenet 4<br /><br />A high performing and reliable colleague decided to put in his papers because he wanted to migrate to the US.<br /><br />What are you assessing?<br />Do her aspirations align with what you can offer her? And this is not just about compensation and benefits. But more importantly , a match between career aspirations and available growth paths in your organization.<br /><br />Would love to hear your views , especially if you disagree or have a contrarian opinion. Keep them coming…<br />"
		} ,
	
		{
		  "title" : "Money, get away, Get a good job with more pay and you're OK?",
		  "category" : "career",
		  "url" : "/career/money-get-away-get-a-good-job-with-more-pay/",
		  "date" : "2017-10-23 00:00:00 +0530",
		  "content"	: "Many commentators , most of them far wiser than me , have coined brilliant terms to refer to the generation gap that exists in the Indian demographic today. Since the workplace is but a small subset of the overall demographic , this generation gap is equally alive and kicking there as well.<br /><br /><br />In my humble view , the workforce in any organization can be divided into two generations:<br /><br />Those who completed schooling before the turn of the millennium , and<br />Those who did so in the present century<br /><br /><br />I’d like to see the former as the RKM (Roti Kapda Makaan) generation , whereas the latter is more of the YOLO/FOMO (You Only Live Once/Fear Of Missing Out) kind. I neither desire , nor possess the ability , to perform a cost-benefit analysis of either approach towards personal finance. However , running the risk of generalization , this is probably how each generation judges the other:<br /><br />RKM (judging YOLO/FOMO): Where are your savings? How can you blow up your entire salary within the first fortnight? Let me show you how to manage your finances.<br /><br />YOLO+FOMO (judging RKM): Papa don’t preach! Get a life!<br /><br />Irrespective of whether money is funny or not for you or whether you desire to write a suicide note on a hundred-dollar bill , you cannot escape the thrill (or chill) of earning your first few pay-checks! And this is arguably one of the primary transformations you’ll experience as you transition from being a student to a professional in your chosen place of work. But as Uncle Ben advised Peter Parker (aka Spiderman) , with great power comes great responsibility…<br /><br />What’s fantastic is , that the power is yours to wield and whether you want to do so responsibly or not , is entirely your choice!<br /><br />"
		} ,
	
		{
		  "title" : "To the Goth Kids",
		  "category" : "career",
		  "url" : "/career/to-the-goth-kids/",
		  "date" : "2017-07-28 00:00:00 +0530",
		  "content"	: "<br /><br />It seems like only recently , startups would hire folks to do just about everything , all at once , and then somehow , we’ve arrived at a ‘Product Manager of Paytm Experience’. How tunnel vision syndrome is eroding the startup spirit.<br /><br /><br />Recently , a startup valued at around half a billion dollars laid off 10 of its Product Managers , leaving them with another 30. Just last year , the same startup hired Product guys at 20–30% premium from the market at average CTCs well over ₹20L. Even more intriguing , some of these guys were techie turned MBAs with less than four years’ experience. Having always been on the sales side of things , where one had to justify a minimum of 4x one’s salary to the company , I was fascinated by this lot. What did they do that was worth that much money?<br /><br />One product guy I spoke to said he managed Paytm experience; which meant he had to ensure there were no drop-offs when the user chose to pay through Paytm. He also said he was mandated to prioritise payment through Paytm. And there were similar folks for each of the other alternate payment processes. “But , is Paytm the most competitive payment solution?” , I asked. He didn’t care , really. All that mattered was ‘mukesh23’ got through paying on the platform without , gods forbid , choosing to click on the refresh button. Even better if he came through one of the exclusive Paytm promotions that he had brokered with his counterpart from the other side.<br /><br />Evidently , the metric for success — # completed transactions , is not entirely off-base. A good product guy could save the company millions , potentially. But , on closer observation it seems as though his chutzpah might also cost the company millions , if not more. In the above case , there are several problems with how the roles are structured. What if Paytm wasn’t the best payment option on the platform? What if (plain conjecture , here) it were costlier , for instance? What if these users exited the native platform at rates higher than average?<br /><br />Let’s leave those seemingly troubling questions aside for a moment. What does one do to improve a third party payment experience? Mainly , vary size and placement of the button , apparently. Turns out , there isn’t much you can do. But , that doesn’t mean you can’t do nothing. So , if you notice a needless “improvement” in your experience , know that some Product Manager’s review is forthcoming. Then , is it a surprise , really , that when things take a turn for the worse , these lot are first in the line of fire? I was surprised , though , to understand that a lot of them were entirely at peace with the transitional nature of their employment. 30% elsewhere , then.<br /><br />This is not restricted to Product folks alone , although it does seem like in recent years it has become a “get rich scheme” of sorts for some techies with an acute propensity to bullshit their way through things. I see Marketing Managers who can’t / won’t write a line of copy or tweak keywords on their website. I see Designers who can’t / won’t code simple HTML or work on user personas and flow maps. I see Engineers who can’t / won’t test their code or learn how to write coherent software requirement specifications. This is manifestly due to the over-specialisation of roles and warped organisation structures in these startups. Ergo , the bleeding disinterest.<br /><br />It wasn’t always like this. It used to be that startups hired people to do just about everything , all at once.<br /><br />Fresh out of college , I was hired as a ‘Management Trainee’ , which I came to realise was code for will do whatever the hell it takes to move the needle. In the first year alone I did Sales , Product , Operations , and Marketing. I wasn’t alone; it seemed like everybody did everything. I remember our VP-Technology managing client delivery for a new initiative , and doing a damn good job at that. I remember our Operations Manager writing bizarre VBA Macros for Excel that saved hours of effort. And it seemed everybody everywhere else , too , were running an arm and a leg short of the work that was on their plates. It was synonymous with startups.<br /><br />It made tremendous business sense , too. First , it was easier to find (and afford) people at the median levels of overlapping skill sets than at the top 1% of their specialisations. Second , people always had a macro view of the company’s goals and everybody , more or less , aligned their personal work accordingly. Third , it had unexpected , yet , massive pay-offs for our chosen specialisations: techies wrote better code because they understood business and sales guys were more effective because they knew the real implications of that code. It wasn’t easy , but those years probably had the greatest impact in my life. It schooled my thoughts and perspectives.<br /><br />When people ask me what changed over the years , I give them the following analogy: a startup , back in the day , was like a goth band. It attracted the misfits , the weirdos , and those of us who just happened to stumble into the mosh pit. There was a ton of work to do and very little real money to be made. You belonged to somewhat of a cult and expected unreasonable things of yourself and your brethren. What we lacked in resources we made up for with ingenuity and perseverance. Over the years , however , the goth band got a makeover. We couldn’t have been more thrilled at that time. It seemed like the World was finally giving us our due. We didn’t have to explain to mothers , uncles and landlords , what we did for a living. We could finally afford EMIs.<br /><br />But , gradually , the goth kids turned cool. The makeup , now , seemed superficial and the cult constantly disowned its own — for how much wisdom can be gained from tweaking button sizes over years? The law of diminishing marginal returns applied: increasing number of new members to the cult caused the marginal product of others to be smaller than the marginal product of the previous members at this point. And that’s how we got ‘Product Manager of Paytm Experience’.<br /><br />But , what of the goth kids? They do lurk around. You won’t find them in conferences or hackathons or by the vending machines mooching off’ the free stuff. They’re likely in an intimate corner , head immersed in the laptop , being productive and maybe checking on Twitter once a while. If you’re ever in the position of hiring for your startup , my suggestion is for you to find and hire the goth kid. He’ll remind you why you started up in the first place. And also , he won’t ask you about your company’s pet policy.<br /><br /><br /><br />  This article was originally published  on Medium. We are republishing it here with the permission of the author<br /><br /><br /><br />"
		} ,
	
		{
		  "title" : "Setting up OAuth2 callbacks in Rails with HTTPS offloading on load balancers",
		  "category" : "technology",
		  "url" : "/technology/setting-up-elb-plus-nginx-with-https-offloading/",
		  "date" : "2017-03-08 00:00:00 +0530",
		  "content"	: "“HTTPS everywhere” is not a luxury anymore. It is a necessity. Thankfully , obtaining an SSL certificate has become easier too , with initiatives such as Let’s Encrypt , GeoTrust , Positive SSL , StartSSL. Even cloud based services such as Cloudflare and Amazon AWS provide free SSL certificates to their customers.<br /><br />####Here is setting some context to help the reader appreciate the discussion:<br />We host our rails applications on Amazon AWS. We generally use three different environments - development , staging and production. Development environment is generally local to a developer while staging and production are hosted on the cloud. There is a minor difference in the way we configure our staging and production environments. Our staging environment typically contains a single machine instance hosting our application. This single instance is exposed to internet directly (has a public IP). On the other hand , our production environment typically contains a cluster of instances for the sake of horizontal scaling. These instances typically do not have a public IP and hence not exposed to internet directly. We put this cluster behind an internet-facing Elastic Load Balancer (ELB).<br /><br />We use chef-solo to manage our cloud infrastructure as well as to deploy code to various environments.<br /><br />#####The Problem Statement:<br />For the sake of this discussion , we shall limit ourselves to configuring SSL certificates obtained from the two free providers , namely Let’s Encrypt and Amazon AWS.<br /><br />Using Let’s Encrypt in a clustered setup is tricky , since you need to make one of the instances stateful , in the sense , one instance needs to be given the responsibility of obtaining and renewing SSL certificate from Let’s Encrypt. All other instances need to copy this certificate every time its renewed. This requirement unnecessarily complicates the setup and also takes away some amount of flexibility. Also , Let’s Encrypt does not issue wildcard certificates and the validity of a certificate is just 90 days<br /><br />The certificates provisioned from the other provider , Amazon AWS , can only be installed on an ELB. Hence is best suited for our clustered setup , namely production. An added advantage is that Amazon can issue wildcard certificates. We could always add an ELB to our staging environment (even though we will never have more than one instance) , but that costs extra money for no reason.<br /><br />This leaves us with these options<br /><br /><br />  <br />    Environment<br />    Best Option<br />  <br />  <br />    Staging<br />    Let's Encrypt<br />  <br />  <br />    Production<br />    Amazon AWS<br />  <br /><br /><br />We went ahead with this choice. Using chef to manage our setup came handy.<br /><br />We first configured our Staging environment and everything worked as expected.<br /><br />However , the same application , in production environment , started throwing CSRF detected Error whenever an OAuth2 callback happened. This was really strange. Our application integrated with two different OAuth providers , and the problem was consistent with both these providers.<br /><br />#####What’s the issue?<br /><br />The only difference between our Staging and Production setups was the ELB.<br /><br />In production , we offloaded HTTPS at the ELB. Plain HTTP request would hit the NGINX web server , which in turn would reverse-proxy it to unicorn and rails.<br /><br />CSRF detected was clearly an error emitting from the rails application. Not from NGINX , and not from the ELB.<br /><br />A closer look would reveal that the rails application had no way to know if the callback was made on a http:// URL or a https:// URL , because it sees only HTTP (due to offloading).  Was this the reason rails was unhappy?<br /><br />OAuth2 , by design , does not accept plain HTTP callbacks (unless it is to localhost).<br /><br />####How do we move forward?<br /><br />#####PoC to prove the theory<br /><br />Just to confirm what we think is the cause , we enabled HTTPS on NGINX (like we did in our staging environment). This was in addition to HTTPS on the Load balancer. We reconfigured the Load Balancer to NOT offload HTTPS but forward the request as-is to NGINX.<br /><br />What do we have now? The CSRF detected errors are gone. Application behaves just like it should.<br /><br />This confirmed our theory.<br /><br />But the question now is , how do we achieve our desired configuration of offloading HTTPS at the ELB ? Is it just not possible ?<br /><br />The Solution<br /><br />We have been using X-Forwarded-For header while reverse proxying to unicorn so that our rails application knows the client IP address (rather than the IP address of the Load Balancer). We need this for logging and tracking.<br /><br />Could there be something on similar lines to tell the rails application that the request was not on HTTP but on HTTPS?<br /><br />Sure there is. We had to set a header in our reverse proxy configuration:<br /><br />X-Forwarded-Proto  to  https<br /><br /><br />For NGINX , we do it like this:<br /><br />  proxy_set_header X-Forwarded-Proto https;<br /><br />Voila , Rails is happy and things are back to normal!<br /><br />Details:<br /><br />Csrf detected!<br /><br />Rails bothers about SSL only at two places , <br /><br /><br />  At environment config , force_ssl.<br /><br />  At external included Gem like Omniauth. <br /><br /><br /><br />In Rails environment config.<br /><br />  config.force_ssl = true<br /><br />This does the trick , but doesn’t seem like a good idea to enable this option in Rails because , we offload https at NGINX. For Rails , request came in http , so it does a permanent redirect to https , which ends in a infinite loop.<br /><br />Our stack trace gave a clue that error might be inside omniauth gem.<br /><br /><br />    actionpack-4.2.7.1/lib/abstract_controller/base.rb:132 → process<br />    actionview-4.2.7.1/lib/action_view/rendering.rb:30 → process<br />    actionpack-4.2.7.1/lib/action_controller/metal.rb:196 → dispatch<br />    actionpack-4.2.7.1/lib/action_controller/metal/rack_delegation.rb:13 → dispatch<br />    actionpack-4.2.7.1/lib/action_controller/metal.rb:237 → block in action<br />    actionpack-4.2.7.1/lib/action_dispatch/routing/route_set.rb:74 → dispatch<br />    actionpack-4.2.7.1/lib/action_dispatch/routing/route_set.rb:43 → serve<br />    actionpack-4.2.7.1/lib/action_dispatch/journey/router.rb:43 → block in serve<br />    actionpack-4.2.7.1/lib/action_dispatch/journey/router.rb:30 → each<br />    actionpack-4.2.7.1/lib/action_dispatch/journey/router.rb:30 → serve<br />    actionpack-4.2.7.1/lib/action_dispatch/routing/route_set.rb:817 → call<br />    omniauth-1.3.1/lib/omniauth/strategy.rb:186 → call!<br />    omniauth-1.3.1/lib/omniauth/strategy.rb:164 → call<br /><br /><br />As we dug inside the Gem and found out that Omniauth looks at these headers<br /><br />lib/omniauth/strategy.rb#L493-L499<br /><br />def ssl?<br />  request.env[&amp;#39;HTTPS&amp;#39;] == &amp;#39;on&amp;#39; ||<br />  request.env[&amp;#39;HTTP_X_FORWARDED_SSL&amp;#39;] == &amp;#39;on&amp;#39; ||<br />  request.env[&amp;#39;HTTP_X_FORWARDED_SCHEME&amp;#39;] == &amp;#39;https&amp;#39; ||<br />  (request.env[&amp;#39;HTTP_X_FORWARDED_PROTO&amp;#39;] &amp;amp;&amp;amp; request.env[&amp;#39;HTTP_X_FORWARDED_PROTO&amp;#39;].split(&amp;#39; ,&amp;#39;)[0] == &amp;#39;https&amp;#39;) ||<br />  request.env[&amp;#39;rack.url_scheme&amp;#39;] == &amp;#39;https&amp;#39;<br />end<br /><br />This is where we found that setting up X_FORWARDED_PROTO to https should fix our problems.<br /><br />Initially , this X_FORWARDED_PROTO was set to $scheme. Which will be http for production as https is offloaded at ELB.<br /><br />Now , by setting X_FORWARDED_PROTO to https , we are making sure that redirects are happening on https.<br /><br />"
		} ,
	
		{
		  "title" : "Custom Capacity Buffers In Go",
		  "category" : "technology",
		  "url" : "/technology/custom-capacity-buffers-in-go/",
		  "date" : "2015-03-31 00:00:00 +0530",
		  "content"	: "At elitmus we use ruby to create most of our tools and most of our applications  are also written in ruby. Recently I started exploring ways to build our tools especially the backend tools in languages other than ruby which have much lesser memory footprint and better efficiency. One such cases was to create a sandboxed environment for running  untrusted code on our servers. After evaluating multiple languages , I decided to use golang because of it’s excellent library support coupled with the fact the docker(a sandboxed env) was also written in go.<br /><br />One of the many challenges we faced while creating our sandbox was  redirection of the standard output of untrusted code , as this simple code below will fill up the disk if redirected to file or use all system resources if redirected to a buffer.<br /><br />1 while(true) printf(“I am the green monster”);<br /><br />So the problem is ,how to limit the size of a file or buffer? , I  started with   buffers  as they are more easy to implement.  I assumed that the Write method of the Buffer struct which writes to the buffer , will panic with ErrTooLarge error if buffer size is above it’s capacity , which i hoped to catch using recover builtin function.<br /><br />This is the code snippet below.<br /><br /> 1    defer func() {<br /> 2       if r := recover(); r != nil {<br /> 3          fmt.Println(&ldquo;Should catch if anyone panics&ldquo;)<br /> 4       }<br /> 5    }()<br /> 6   a := bytes.NewBuffer(make([]byte , 0 , 2))<br /> 7   for {<br /> 8     _ ,err := a.Write([]byte(&ldquo;create boom&ldquo;))<br /> 9     if err != nil {<br />10       fmt.Println(err.Error())<br />11        return<br />12     }<br />13 <br />14   }<br /><br />On running this code , my system was frozen and crashed a little later. This is not what i expected , On further investigation by looking to source code and reading the bytes package documentation again , i found out that Write method in the bytes package is growing the capacity of the  buffer if the buffer capacity is not enough , which in turn is increasing the amount of memory and resources used by the system.<br /><br />After some googling and with good help from the go community(thanks to dave cheney) , i decided  to create wrapper around the buffer struct and implement my own io.Writer interface by implementing Write method for the wrapper which writes to the buffer.<br /><br />My custom wrapper’s will take capacity as parameter when initializing and the Write method will do the required action if there is a buffer overflow , instead of increasing the capacity like the Write method from bytes package. This is done by monitoring the size of the buffer before writing to the buffer.<br /><br />This is code snippet of my custom wrapper.<br /><br /> 1 type MyBuffer struct {<br /> 2     cap   int<br /> 3     mybuf *bytes.Buffer<br /> 4 }<br /> 5 <br /> 6 func (b *MyBuffer) Write(p []byte) (n int , err error) {<br /> 7     if len(p)+b.mybuf.Len() &#62;; b.cap {<br /> 8         fmt.Printf(b.mybuf.String())<br /> 9         panic(&ldquo;Buffer Overflow&ldquo;)<br />10     } else {<br />11         b.mybuf.Write(p)<br />12     }<br />13     return len(p) , nil<br />14 }<br />15 <br />16 func NewBuffer(buf []byte , cap int) *MyBuffer {<br />17     return &amp;amp;MyBuffer{mybuf: bytes.NewBuffer(buf) , cap: cap}<br />18 }<br />19 <br />20 func main() {<br />21 <br />22     defer func() {<br />23         if r := recover(); r != nil {<br />24             fmt.Println(&ldquo;recover in yes&ldquo;)<br />25         }<br />26     }()<br />27 <br />28     a := NewBuffer(make([]byte , 0 , 100) , 200)<br />29     for {<br />30         _ , err := a.Write([]byte(&ldquo;Check for Buffer Overflow&ldquo;))<br />31         if err != nil {<br />32             fmt.Println(err.Error())<br />33             return<br />34         }<br />35     }<br />36 }<br /><br />On running this code , it worked as expected , hopefully will be deployed in production.<br />The same goes for files as well.<br /><br />Note: useful links , on docker ,on golang bytes package<br /><br />"
		} ,
	
		{
		  "title" : "Making Airtel 3G dongle work on Mac OS 10.10 Yosemite",
		  "category" : "technology",
		  "url" : "/technology/making-airtel-3g-dongle-work-on-mac-os-10-dot-10-yosemite/",
		  "date" : "2014-12-03 00:00:00 +0530",
		  "content"	: "If you use Airtel 3G Dongle (Mine is Huawei E173) on your Mac , and are having issue using the dongel after upgrading to Yosemite , airtel is of little help. They asked me to downgrade the OS to Mavericks!<br /><br />The reason why the dialer software provided by airtel does not work is , that they internally use Apple USB Modem. According to this FAQ on apple support site , your Operating system should be running in 32 bit mode for the modem to work. Yosemite however , is 64 bit.<br /><br />Anyway , I could find multiple ways to overcome the problem. Here I am writing about the most simple one<br /><br />###Step 1: <br />Click on this link to download the new compitable driver from Huawei website Mac-V200R003B015D11SP00C983(for Mac10.10).rar<br /><br /><br /><br />###Step 2: <br />Open the archive , you will find two files<br /><br />1. Mobile Partner install user guide.docx<br />2. Mobile Partner.zip<br /><br /><br />The word document has detailed instructions with screenshots , on how to install.<br /><br />###Step 3: <br />Open the zip file Mobile Partner.zip , you will find Mobile Partner.app. Double click on this file to install the app<br /><br />###Step 4: <br />Once installed , start the app and go to Tools -&#62;; Options<br /><br /><br /><br />###Step 5: <br />In the Options window , choose “Profile Management” from the left side menu<br /><br /><br /><br />###Step 6: <br />Click on “New” button to create a new profile. Give it a name , such as “airtel 3g”. Also , make sure the “Access Number” is set to *99#. Click “Save” , then “Ok”.<br /><br /><br /><br />###Step 7: <br />Insert your Dongel into an USB port. You should see “Mobile Partner” application starting automatically. Choose the profile you created in Step 6 (“airtel 3g”) and “Connect”.<br /><br /><br /><br />That’s it.<br /><br />"
		} ,
	
		{
		  "title" : "IT Career - Pitfalls to avoid",
		  "category" : "career",
		  "url" : "/career/it-career-pitfalls-to-avoid/",
		  "date" : "2014-09-22 00:00:00 +0530",
		  "content"	: "It is very humbling when a youngster walks up to us and says “Thanks for helping me get my first job”. While we are delighted at one end , we are worried at the other.  Why? Because , most of the time a fledgling mind does not see the disaster ahead! Yes , we mean disaster – 75% of IT professionals of 2011-2014 batches will be unemployed 20 years from now.  And this is assuming IT industry does well !! Looks unlikely? Read on to know more.<br /><br />Indian IT industry has employed around 7 ,50 ,000 professionals from the four batches (2011 , 2012 , 2013 , 2014). An estimated 1 ,50 ,000 of these will leave the Indian IT industry to pursue higher studies and never come back to work for the same industry. That leaves us with 6 ,00 ,000 professionals who will be in the industry for long. The question is: How long? Being highly paid with around 20 years of experience , in the year 2030 , companies would want them to take larger responsibilities and oversee at least 100 professionals under them. Summing it up , these 6 lakh professionals should have 6 crore professionals below them. Assuming IT industry grows at 10% per annum for 20 years (caution - it may already be slowing down) , the whole industry will be just 1.2 crore strong. That means at most 1.2 lakh senior professionals will be needed. What would happen to the rest 4.8 lakh professionals? They would , of course , be unemployed.<br /><br />Difficult to digest? In 1995 , there were approximately 11 ,000 software professionals across all levels. Nearly 50% of them are now citizens of another country or earned enough money from the exponentially growing market (nascent market then) growing market to retire , appropriately called VIP (vested in peace). Another at most 15 ,500 professionals of the same era migrated into IT industry from other industries (like SAP consultants , Supply Chain , Financial professionals). So that is a conservative 21 ,000 senior professionals in the whole of Indian IT industry. Many of these who lose a job today struggle to find another suitable profile (20 Yrs of experience) and this is when growth rates in this period have been over 25%. You can see it happening for the current 40+ year old professionals!!<br /><br />Now you have a lingering doubt – could there be something wrong in the projections? Yes !! But it is unfortunately on the negative side. What if the industry grows slower than 10% (may be another bad patch of no growth for 2-4 years). What if automation makes many more jobs redundant (now in IT itself , think about it!)? Last but not the least , another country taking away jobs from India (like China did in manufacturing)?<br /><br />A tell-a-tale from not very long ago is the textile mills of Bombay. They were teeming with activity and nothing could go wrong for them in 1970s and early 1980s. It could only get better as population was growing and people’s ability to spend was increasing. These very mills today are malls!! It can be argued to be a ‘crowding out’ phenomenon , surely not applicable to sunrise IT industry. Or maybe it is visible only in hindsight !!!<br /><br />What are we doing at eLitmus to help the cause?<br /><br /><br />  <br />    We are pushing companies not to lower the entry barriers. We have found that immediately after a slow down year , quality and quantity of candidates improve. Quantity ok , but how quality? You call it competition , you call it lowered demand or call it buyers market. So if companies can adopt the quality principals in this period , why not in growth phase as well. It will help students also.<br />We strongly believe a youngster`s ability to adapt and evolve is much higher than an older person. So push them today rather than tomorrow. If you remember your grandparents had the fitness and ability to walk kilometres at their old age (not spoilt by automobiles when they were a child)<br />  <br />  <br />    Educating students that the easy path out , though rosy for short term , will destroy them. We want them to go that extra mile. That explains our rigorous question paper which tests fundamentals and concepts. We want them to earn their job rather than get it. In the process their ability goes up. Few students who wrote pH test in the initial years of eLitmus have founded their own start-ups.<br />  <br />  <br />    Ensuring start-ups and companies with great work environment do not struggle for lack of talent. Most of these engagements are loss making. We survive thanks to the fact that most of our colleagues at eLitmus are passionate about what they do and work at a fraction of their market salary!!<br />  <br /><br /><br />We are committed to “making India competitive” and we hope we have challenged the young reader of this blog to go the extra mile. As Steve Jobs once quoted the Whole Earth catalogue “Stay hungry , Stay foolish!”<br /><br />"
		} ,
	
		{
		  "title" : "How we host our blog on GitHub pages and yet serve it from our own Sub-URL",
		  "category" : "technology",
		  "url" : "/technology/how-we-host-our-blog-on-github-pages-and-yet-serve-it-from-our-own-sub-url/",
		  "date" : "2014-08-18 00:00:00 +0530",
		  "content"	: "There are umpteen number of blog posts telling you how to host your static site on GitHub Pages for free. They also tell you how to serve such a site from your own domain name.<br /><br />As you may have guessed , this blog is also hosted on GH Pages. Don’t believe me? try visiting this URL https://shireeshj.github.io/blog/<br /><br />It is easy to map a github.io url such as this , to a subdomain. For example , it is easy to map the url to https://blog.elitmus.com/blog/.  All you need to do is check-in a file named CNAME into the root folder of your git repo that contains your static site.<br /><br />What if you want your static site to be served from domain apex? That is easy too.  GitHub pages help explains this in a simple manner.<br /><br />However , If your domain apex is already taken , say by your other website , you have a problem.  To host your static site on a domain apex (or a sub-url of domain apex) the domain apex should be available exclusively for use by github pages.<br /><br />We had to overcome this very problem , since our business website is already hosted on elitmus.com (and www.elitmus.com).  Given that we are not in great love with subdomains. We had to find a workaround. And here is what we did:<br /><br />Since we use nginx to server our business website , all we had to do was to write a simple traffic-cop rule. What this rule did was , to parse the request url to see if it starts with /blog/. If yes , then the request is reverse proxied to GitHub Pages. If no , then it is served from local disk.<br /><br />The relevant lines from the config file are here<br /><br /><br/>location /blog/ {<br /><br/>    proxy_pass       http://shireeshj.github.io/;<br /><br/>    proxy_redirect off;<br /><br/>    proxy_set_header Host &#60;;shireeshj.github.io&#62;;;<br /><br/>    proxy_set_header X-Host &#60;;shireeshj.github.io&#62;;;;<br /><br/>    proxy_set_header X-Real-IP $remote_addr;<br /><br/>    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;<br /><br/>  }<br /><br /><br />This is how we get free hosting for our blog , yet serve it from our official URL. If GitHub pages ever stops us from reverse proxying , we shall simply spin our own webserver to run this static site and reverse proxy to that web server.<br /><br />"
		} ,
	
		{
		  "title" : "Using Monit to get email alert on unauthorized login",
		  "category" : "technology",
		  "url" : "/technology/using-monit-to-get-email-alert-on-unauthorized-login/",
		  "date" : "2014-06-04 00:00:00 +0530",
		  "content"	: "For a long time , we had our own custom written perl script to alert us whenever someone logged into our production servers from an ip address we do not recognize (not whitelisted). The script looked somewhat like this…<br /><br />#!/usr/bin/perl<br /># script file: alert_on_login.pl<br />#<br />my $login_str = &ldquo;Accepted publickey&ldquo;<br />my $whitelist_ip = &ldquo;122.123.123.111&ldquo;<br /><br />sub sendEmail<br />{<br />        my ($to , $from , $subject , $message) = @_;<br />        my $sendmail = &amp;#39;/usr/lib/sendmail&amp;#39;;<br />        open(MAIL , &ldquo;|$sendmail -oi -t&ldquo;);<br />        print MAIL &ldquo;From: $from&ldquo;<br />        print MAIL &ldquo;To: $to&ldquo;<br />        print MAIL &ldquo;Subject: $subject&ldquo;<br />        print MAIL &ldquo;$message&ldquo;<br />        close(MAIL);<br />}<br /><br />while (&#60;;&#62;;) {<br />        if (grep(/$login_str/ , $_) &amp;amp;&amp;amp; !grep(/$whitelist_ip/ , $_)) {<br />                print $_;<br />                chomp $_;<br />                @arr = split(&amp;#39; &amp;#39; , $_);<br />                sendEmail(&amp;#39;recepient1@elitmus.com , recepient2@elitmus.com&amp;#39; ,<br />                          &amp;#39;monit@elitmus.com&amp;#39; ,<br />                          &amp;#39;Server login from &amp;#39; . $arr[10] ,<br />                          $_);<br />        }<br />}<br /><br />All we needed to do was to run this script in the background as a daemon , and it would send us an email alert whenever someone logged in successfully. As root user start the script like this:<br /><br />  # (perl alert_on_login.pl /var/log/auth.log &amp;amp;)<br /><br /><br />Ever since we started using monit for the usual purpose (monitoring processes) , we have also entrusted monit to do the job of the above perl script. Monit makes this super simple…<br /><br />Monit is a popular opensource process monitoring tool. It is used mostly for monitoring health of any linux process and take necessary action if any of the set parameters are breached. Monit can restart a process if the process failed for some reason. Monit can also notify you of incidents and actions taken.<br /><br />See this to learn more about monit’s alert capabilities.<br /><br />Monit’s global configuration file is usually /etc/monit/monitrc. Here is what monit needs to be told about how to send email alerts:<br /><br />...<br /># This is our SMTP server settings. The complete syntax is<br /># SET MAILSERVER &#60;;hostname [PORT] [USERNAME] [PASSWORD] [using SSLAUTO|SSLV2|SSLV3|TLSV11|TLSV12] [CERTMD5 checksum]&#62;; , ...<br />#          [with TIMEOUT X SECONDS]<br />#          [using HOSTNAME hostname]<br />#<br /># But for our purpose , localhost is good enough<br />SET mailserver localhost<br /><br /># This is the email template for alert messages<br />SET mail-format {<br />  from: monit@elitmus.com<br />  subject: $SERVICE $EVENT at $DATE<br />  message: Monit $ACTION $SERVICE at $DATE on $HOST: $DESCRIPTION.<br />           Yours sincerely ,<br />           monit<br />}<br /><br /># Alerts can be triggered for various reasons. Successful ssh login is just one of those reasons.<br /># Since this is a global configuration , we can tell monit to not send alerts for certain events<br />#  We also specify the email address of the recepient who will receive the alerts<br /><br />set alert recepient1@elitmus.com NOT ON { action , instance , pid , ppid , nonexist }<br />...<br /><br />And then we add this config file ssh_logins.conf specific to sshd related stuff:<br /><br />check file ssh_logins with path /var/log/auth.log<br />  ignore match &ldquo;/etc/monit/whitelist_ips.regex&ldquo;<br />  if match &ldquo;Accepted publickey&ldquo; then alert<br /><br />Notice how we tell monit to ignore logins from known ip addresses. We can now store all whitelist ip addresses in a separate file /etc/monit/whitelist_ips.regex , one address per line.<br /><br />Note: We have disabled password based login and hence do not monitor for passworded logins. If you use passworded login , you should change &quot;Accepted publickey&quot; to &quot;Accepted password&quot;<br /><br />Happy monitoring!<br /><br />"
		} ,
	
		{
		  "title" : "Gotcha's while syntactically translating AES encryption logic from PHP to Ruby",
		  "category" : "technology",
		  "url" : "/technology/gotchas-while-syntactically-translating-aes-encryption-logic-from-php-to-ruby/",
		  "date" : "2014-05-25 00:00:00 +0530",
		  "content"	: "Our Payment Gateway service provider recently launched a new platform with some nice-to-have features. We wanted those features and so we decided to migrate. Being one of the earliest adopters of the new platform , there was no integration kit available. We had to build it ourselves. Not a problem. Since we are a Ruby On Rails shop , we built our own Ruby integration kit. All went well and we pushed it to production.<br /><br />A month or two later , we got an email from our gateway provider seeking our help with writing the encryption and decryption logic for the Ruby integration kit they were developing. We were a little surprised , because we noticed they had already published integration kits for PHP , Python , JAVA etc. How difficult can it be to translate that to Ruby?<br /><br />Turns out , syntactic transalation of code from one programming language to another does not always work. A slightly more deeper knowledge helps. We could almost guess where they were getting stuck.<br /><br />Before we get to the story , some backgroung on the encryption algo will add clarity.<br /><br />For secure communication between our server and the gateway , the prescribed cipher was AES , specifically symmetric-key block cipher with a 128 bit secret key in CBC mode. Since OpenSSL already implements this algo and is avaliable on almost all platforms , most programming languages just bundle a wrapper for OpenSSL.<br /><br />So if its the same OpenSSL that the wrappers call , why couldn’t the gateway service provider translate their own PHP code to Ruby?<br /><br />Here is why:<br /><br />AES works by breaking the plain text (the text to be encrypted) into blocks of 128 bits (or 16 bytes). In CBC mode , each block is XORed with the key to get cipher text of that block. The cipher text of the previous block is used for encrypting the next block… so on and so forth , until all the blocks are encrypted.<br /><br />Note that the length of the cipher text will be exactly same as that of the plain text.<br /><br />The problem occures with the last block. If the length of the plain text is not a multiple of 128. the last block will be shorter than 128 bits. Since the algo can work only on blocks of 128 bits , It is a common practice to pad the last block so that it becomes equal to 128 bits in lenght. This padding is subsequently discarded after decryption.<br /><br />Note: The actual algo is more complicated than this. We have deliberately left out details that are not relevent for this post.<br /><br />This is the encryption method in the PHP integration kit published by the gateway service provider<br /><br /> 1 function encrypt($plainText ,$key)<br /> 2 {<br /> 3   $secretKey = hextobin(md5($key));<br /> 4   $initVector = &ldquo;...&ldquo;<br /> 5   $openMode = mcrypt_module_open(MCRYPT_RIJNDAEL_128 , &amp;#39;&amp;#39; ,&amp;#39;cbc&amp;#39; , &amp;#39;&amp;#39;);<br /> 6   $blockSize = mcrypt_get_block_size(MCRYPT_RIJNDAEL_128 , &amp;#39;cbc&amp;#39;);<br /> 7 <br /> 8   $plainPad = pkcs5_pad($plainText , $blockSize);  //  &#60;;---- Padding<br /> 9 <br />10   if (mcrypt_generic_init($openMode , $secretKey , $initVector) != -1) <br />11   {<br />12     $encryptedText = mcrypt_generic($openMode , $plainPad);<br />13     mcrypt_generic_deinit($openMode);      <br />14   } <br />15   return bin2hex($encryptedText);<br />16 }<br />17 <br />18 // Padding method<br />19 function pkcs5_pad ($plainText , $blockSize)<br />20 {<br />21   // padding logic here<br />22 }<br /><br />And here is the same implemented in Ruby<br /><br />1 def self.encrypt(plain_text , key)<br />2     secret_key     = Digest::MD5.digest(key)<br />3     cipher         = OpenSSL::Cipher::AES.new(128 , :CBC)<br />4     cipher.encrypt<br />5     cipher.key     = secret_key<br />6     cipher.iv      = INIT_VECTOR<br />7     encrypted_text = cipher.update(plain_text) + cipher.final<br />8     return (encrypted_text.unpack(&ldquo;H*&ldquo;)).first<br />9 end<br /><br />Notice any difference?<br /><br />It turns out that , unlike in Python , PHP and few other languages , Ruby wrapper for OpenSSL automatically takes care of padding (default behaviour). This is clearly mentioned in the documentation. For some reason , techies at our gateway service provider overlooked this and hit a dead-end.<br /><br />By the they , they were gracious enough to acknowledge our contribution in their Ruby Integration Kit (accessible only to their subscribers)<br /><br />But We have open sourced our code here ‘cca_crypto’. We have plans of make this into a complete package - with view generators etc. , and publish this as a rubygem. We shall gladly accept any pull request!<br /><br />"
		} ,
	
		{
		  "title" : "Setting Up Amazon RDS as a Slave to a self-managed MySQL server",
		  "category" : "technology",
		  "url" : "/technology/setting-up-amazon-rds-as-a-slave-to-a-self-managed-mysql-server/",
		  "date" : "2014-05-21 00:00:00 +0530",
		  "content"	: "Last week , we migrated our MySQL database server , which was running on an EC2 instance , to RDS. We hoped the migration process would be smooth.<br /><br />As always , migrating a large database has its challenges. Business folks expect the minimum possible downtime.<br /><br />The plan was simple.<br /><br /><br />  Launch an RDS instance<br />  Load a full dump into it<br />  Configure it to act as a slave of the self-managed server (current master)<br />  On the D-day , pull the website down and promote the RDS instance to take over as the new master<br /><br /><br />We soon discovered that RDS comes with curtailed root permissions. There are several commands that are disallowed. Some of these include “CHANGE MASTER TO….”<br /><br />What do we do now?<br /><br />One option was to carry out the migration in one go , while the website was offline. This meant the downtime would have been several hours , instead of minutes. Obviously , not an acceptable option at all.<br /><br />Some R&amp;amp;D was all it took to discover how to proceed with the original approach.<br /><br />RDS comes with a bunch of stored procedures , which help you configure it as a slave. There is almost a one-to-one mapping of these stored procedures with the commands that are disallowed.<br /><br /><br />MySQL CommandCorrosponding Stored Proc<br />CHANGE MASTER TOmysql.rds_set_external_master<br />START SLAVEmysql.rds_start_replication<br />STOP SLAVEmysql.rds_stop_replication<br />RESET MASTERmysql.rds_reset_external_master <br /><br /><br />So , Using these stored procedures , you can now configure your RDS instance as a slave to your self-managed MySQL server<br /><br />After loading a full dump to RDS , Call the stored procedure mysql.rds_set_external_master like this<br /><br />CALL mysql.rds_set_external_master ('servername' , port , 'user' , 'password' , 'binlog-file' , binlog-offset , 0);<br /><br /><br />Then<br /><br />CALL mysql.rds_start_replication;<br /><br /><br />This will make RDS a slave of your self managed mysql server. You can run “SHOW SLAVE STATUS” to see its working.<br /><br />When it is time to promote RDS to master. You call these stored procedures<br /><br />CALL mysql.rds_stop_replication;<br /><br />CALL mysql.rds_reset_external_master;<br /><br /><br />That’s it. Now point your applications to the RDS instance and take your site live.<br /><br />Note:<br /><br />For your RDS to work as a slave , it needs permissions to connect to port 3306 of your current master. Make sure you open this port for the RDS instance.<br /><br />You can run the following command to find out the ip address of your rds instance<br /><br />ping -c rdsname.cpesx66wwe7y.ap-southeast-1.rds.amazonaws.com<br /><br />"
		} ,
	
		{
		  "title" : "Beware of creating $HOME/.ssh folder by hand, when SELinux is turned on",
		  "category" : "technology",
		  "url" : "/technology/beware-of-creating-ssh-folder-by-hand-when-selinux-is-turned-on/",
		  "date" : "2012-07-22 00:00:00 +0530",
		  "content"	: "I was experimenting with chef to manage our Linux boxes. As a standard practice , our application user deployer is homed in /applications/deployer rather than the usual /home/deployer.<br /><br />To enable password less login , I appended my public key to ~/.ssh/authorized_keys<br /><br /> ssh-copy-id -i ~/.ssh/id_rsa deployer@remote.server<br /><br /><br />The first time I run this command , I will be prompted for a password to install my key. After this , I can run the below command to login without a password:<br /><br />ssh -i ~/.ssh/id_rsa deployer@remote.server<br /><br /><br />However , that did not work as expected.<br /><br />For some reason , sshd was unable to read the authorized_keys file. I checked all the usual things.. all looked fine. Everything seem to work just fine when SELinux was running in permissive mode on the remote server , but not when it was in enforcing mode.<br /><br />Discovered that if .ssh folder was created by hand (or even the folder containing .ssh folder) , we need to do few additional things.<br /><br />Step 1:<br /><br />Open this file /etc/selinux/targeted/contexts/files/file_contexts.homedirs and append the following line to the bottom<br /><br /> /applications/deployer/[^/]*/ssh(/.*)?     system_u:object_r:ssh_home_t:s0<br /><br /><br />Note: remember to adjust the path as per your needs.<br /><br />Step 2: run the following command<br /><br />restorecon -R -v /applications/deployer/.ssh<br /><br /><br />Again , remember to adjust the path as per your needs.<br /><br />Now you are all set!<br /><br /> ssh -i ~/.ssh/id_rsa deployer@remote.server<br /><br /><br />should log you in without asking for a password!<br />"
		} ,
	
		{
		  "title" : "Importance of Date field in an email's Header",
		  "category" : "technology",
		  "url" : "/technology/importance-of-date-field-in-an-emails-header/",
		  "date" : "2012-04-04 00:00:00 +0530",
		  "content"	: "So far , we paid little attention to email delivery issues. We knew delivering to rediffmail is a pain. So we discouraged our users from using rediffmail. Apart from that we had FCrDNS and SPF configured and working fine. We had also configured DKIM. And then a month ago , we also added DMARC in monitor mode.<br /><br />We were happy! Until…<br /><br />Recently , we started getting loads of phishing emails from what appeared to originate from our own domain name [not our servers].<br /><br />It told us two things.<br /><br /><br />  eLitmus.com was growing in popularity<br />  We cannot ignore email delivery issue any longer<br /><br /><br />We ran our email through Spam Assassin checks and were surprised to see that we got a score of 6. Anything above 5 is BAD. It’s a straight spam! But we knew we were not spamming. These were transactional emails triggered by our website on certain events , such as New registration , or Forgot Password.<br /><br />It was almost by accident , we noticed that the timezone in the Date header of the email was appearing as +0580. Indian Standard Time (IST) is 5 hours and 30 minutes ahead of UTC. So this value should have been +0530 , not +0580. Apparently , that is good enough reason for Spam Assassin to treat our mails as spam.<br /><br />Tracing backwards , we discovered a bug in our application code and fixed it. It was a single line fix.<br /><br />With this change , Spam Assassin was happy to give us a score of zero.<br /><br />That is just one part of one header. There are ten others which have to be configured correctly.<br /><br />Here is an article with good insights in to how gmail calculates sender reputation. Its a little dated , but still relevent. Sender reputation in a large webmail service (PDF)<br /><br />By the way , here is a nice and free JSon API to check your email’s reputation.<br /><br />"
		} 
	
]